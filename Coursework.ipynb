{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fd4fca06-f3df-4d3d-8465-c493f7879612",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "85307fef-752a-4a8b-86d4-fb6f5d2f3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "22cd635c-7e1e-453a-8324-c2cf1c1812da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to understand this function for now.\n",
    "def load_data_CIFAR10(batch_size, resize=None):\n",
    "    \"\"\"Download the CIFAR10 dataset and then load it into memory.\"\"\"\n",
    "    trans = [torchvision.transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, torchvision.transforms.Resize(resize))\n",
    "    trans = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=2),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f86b1a98-2bd4-4d28-8aa9-b4e8536adb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # Defines the batch size\n",
    "train_iter, test_iter = load_data_CIFAR10(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0ecba6e7-eb01-4ee4-93c4-9ec60f808e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_iter)) # Requests the first training batch\n",
    "print(X.size()) # 256 images per batch. Each image is represented by a 1 x 28 x 28 tensor (number of channels x height x width). The images are grayscale, so there is a single channel.\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "67ff0d21-e530-4f8e-994a-bde7be049a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockGen(nn.Module):\n",
    "    # Creating Intermediate Blocks\n",
    "    # the length of param indicates the number of intermediate blocks\n",
    "    # each parameter is then inside the param for convolutional layers\n",
    "    def __init__(self, in_channels, out_channels, c, layers, paddings, strides, kernels):\n",
    "        super(BlockGen, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        master_model = []\n",
    "        self.c = c\n",
    "        self.layers = layers\n",
    "        for i in range(c):\n",
    "            convs = nn.ModuleList()\n",
    "            for j in range(layers[i]):\n",
    "                convs.append(nn.Conv2d(in_channels[i][j], out_channels[i][j], kernel_size=kernels[i][j],stride= strides[i][j], padding= paddings[i][j]))\n",
    "            master_model.append(convs)\n",
    "        \n",
    "        self.model = master_model\n",
    "        # the fully-connected layer turning m to a to calculate the weights of convolutional layer in the final equation the output should be the same value as the number of concolutional layers\n",
    "       self.fc = nn.Linear(in_channels[0][0], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m = []\n",
    "        for i in range(x.size()[0]):\n",
    "            m.append((float(x[i].flatten().mean())))\n",
    "        m = torch.Tensor(m)\n",
    "        a = self.fc(m)\n",
    "        # creating the convolutional neurons in the layer of the block\n",
    "        x = self.relu(x)\n",
    "        model = self.model\n",
    "        out_list = []\n",
    "        for i in range(self.c):\n",
    "            s.append(0)\n",
    "            mod = mo[i]\n",
    "            out = x\n",
    "            for model in mod:\n",
    "                out = model(out)\n",
    "            print(out.size())\n",
    "            out_list[i] = out\n",
    " \n",
    "        return sum(out_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "406ed366-1730-4f9f-a495-32f60fbb0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModel(nn.Module):\n",
    "    # Creating Intermediate Blocks\n",
    "    # the length of param indicates the number of intermediate blocks\n",
    "    # each parameter is then inside the param for convolutional layers\n",
    "    def __init__(self, num_block, c, layers, in_channels, out_channels, kernels, paddings, strides):\n",
    "        super(FinalModel, self).__init__()\n",
    "        blocks = nn.ModuleList\n",
    "        for i in range(num_block):\n",
    "            blocks.append(BlockGen(c=c[i], layers=layers[i], in_channels=in_channels[i], out_channels=out_channels[i], kernels=kernels[i], paddings=paddings[i], strides=strides[i]))\n",
    "        self.blocks = blocks\n",
    "        self.fc = nn.Linear(in_channels[-1][-1][-1], 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # creating the convolutional neurons in the layer of the block\n",
    "        x = self.relu(x)\n",
    "        model = self.model\n",
    "        out_list = []\n",
    "        for model in self.blocks:\n",
    "            x = model(x)\n",
    "            \n",
    "        for i in range(x.size()[0]):\n",
    "            m.append((float(x[i].flatten().mean())))\n",
    "        m = torch.Tensor(m)\n",
    "        out = self.fc(m)\n",
    " \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb6ae26-f43d-424b-915b-f421766d7619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvBlock(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applies Xavier initialization if the `torch.nn.Module` is `torch.nn.Linear` or `torch.nn.Conv2d`\n",
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "num_outputs = 10\n",
    "model = BlockGen(in_channels=[[3,12],[3,6]], out_channels=[[12,12],[6,12]], c=2, layers=[2,2], paddings=[[2,0],[0,0]], strides=[[1,2],[1,1]], kernels=[[3,2],[3,1]])\n",
    "model.apply(init_weights) # Applies `init_weights` to every `torch.nn.Module` inside `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62987da8-567b-4690-8e9c-2d0a05481ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8fb2b4-1828-4960-81a1-49c84469adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f79f66-bf58-4a62-912a-b4b0931a9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(logits, y):\n",
    "    y_hat = logits.argmax(axis=1) # Finds the column with the highest value for each row of `logits`.\n",
    "    return (y_hat == y).float().sum() # Computes the number of times that `y_hat` and `y` match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440558aa-4038-48a2-9668-ea8b5a882e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metric(model, data_iter, metric):\n",
    "    \"\"\"Compute the average `metric` of the model on a dataset.\"\"\"\n",
    "    c = torch.tensor(0.)\n",
    "    n = torch.tensor(0.)\n",
    "    for X, y in data_iter:\n",
    "        logits = model(X)\n",
    "        c += metric(logits, y)\n",
    "        n += len(y)\n",
    "\n",
    "    return c / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698f82c-1c72-4e07-9305-e07e0c612058",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training accuracy: {evaluate_metric(model, train_iter, correct)}. Testing accuracy: {evaluate_metric(model, test_iter, correct)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45b272-c01e-4e47-8e17-7a7e608f8db5",
   "metadata": {},
   "source": [
    "# Basic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4bfbd-ceea-4b51-97fa-09d673d615d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d41057c-f725-494c-bbe4-7b7a831c6e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.1000, 3.4000, 5.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "n = torch.Tensor([[[1,2,6,4,7],[2,4,3,5,7]],[[1,1,4,3,2],[2,2,7,5,7]], [[1,4,8,4,7],[2,4,8,5,7]]])\n",
    "m = []\n",
    "for i in range(n.size()[0]):\n",
    "    m.append((float(n[i].flatten().mean())))\n",
    "m = torch.Tensor(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0cd44b9-c7ff-4546-bee4-08ef382df462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(3, 5)\n",
    "    def forward(self, x):\n",
    "        out  = self.fc1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b89bd00-cceb-4b54-8c05-c9145cddca14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m k \u001b[38;5;241m=\u001b[39m Model()\n\u001b[0;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m k(\u001b[43mm\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "k = Model()\n",
    "out = k(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d49ca46-e833-480e-8901-7dd53fe67112",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2093479193.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    class OutBlock:\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class OutBlock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f91b7f49-3c31-42db-9be7-542537e00dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{'L': 3,'kernel_size':1 , 'stride':1, 'padding':0}, {'out':3, 'L': 3,'kernel_size':2 , 'stride':3, 'padding':1}, {'out':2, 'L': 5,'kernel_size':2 , 'stride':1, 'padding':0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "46cf72e3-001c-4d4a-8a9a-de0a52949617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L': 3, 'kernel_size': 1, 'stride': 1, 'padding': 0}\n",
      "{'out': 3, 'L': 3, 'kernel_size': 2, 'stride': 3, 'padding': 1}\n",
      "{'out': 2, 'L': 5, 'kernel_size': 2, 'stride': 1, 'padding': 0}\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(param):\n",
    "    print(param[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e94b33b-0144-4ed5-b58d-b0cbab403175",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmod\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mod' is not defined"
     ]
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c519e-7681-4f72-9546-f4b62aaf11d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b36f43-d48d-49b1-b45b-5a30f153f3d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (4252390199.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    mod = Blo\"ckGen(param=param, in_channels=3, out_channels=10)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "mod = Blo\"ckGen(param=param, in_channels=3, out_channels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7a643aa4-6c75-40cd-8f03-4b734488dbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mod(n)\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ecac8036-a2a0-4d43-a700-1296cd511396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4177ff3a-1fe7-4482-9f5b-3cbb372968dc",
   "metadata": {},
   "source": [
    "## Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b41e7467-ee60-42c8-bc44-875ffc24eb2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5916,  0.5676, -1.0415,  0.2531,  1.1415, -1.0663],\n",
       "         [ 1.0914,  0.5812,  0.7329, -0.9620, -3.5427, -0.9107],\n",
       "         [ 0.1481, -0.6351, -2.2436,  0.2195,  0.3712, -0.2928],\n",
       "         [-0.3627, -0.1971, -1.1930,  0.7793, -0.3895,  1.8926],\n",
       "         [ 0.6179,  1.7252, -1.0225, -0.3343, -0.7708, -1.1098],\n",
       "         [-0.8818,  0.1688, -0.0045,  0.5856, -0.9097, -0.2356]],\n",
       "\n",
       "        [[-0.9179,  0.8336, -0.8736, -0.5851,  0.9430,  0.1678],\n",
       "         [ 1.1078,  0.6509,  0.2739,  0.2685,  0.1837, -0.4887],\n",
       "         [ 0.1076, -1.4711, -0.1499,  1.0199,  1.2663,  1.3709],\n",
       "         [-0.8724, -0.8335,  0.5277, -1.7724,  1.4742,  0.6399],\n",
       "         [-0.3226,  0.7655,  0.9605, -0.1787,  0.4703, -1.9245],\n",
       "         [-1.9839, -1.3509, -0.2614, -0.0918, -1.8255, -0.7549]],\n",
       "\n",
       "        [[ 0.1341,  0.6445,  0.7236, -0.3718, -1.1775, -0.1703],\n",
       "         [ 0.8173, -1.1339, -0.3453,  0.7949, -0.0057,  0.5891],\n",
       "         [ 1.2043,  1.0888,  0.1014, -2.1153, -0.5242, -0.2361],\n",
       "         [ 0.5098,  0.5529,  0.3398, -2.0270, -0.3535,  1.3578],\n",
       "         [ 2.2456,  0.7079, -0.0439,  1.6147, -1.6629,  0.1261],\n",
       "         [ 1.3471,  0.7019,  1.9844, -0.9387,  0.5293, -0.4642]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = torch.randn(3,6,6)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a096265e-0a6d-4579-b472-dae3894896ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = nn.Conv2d(3, 12, kernel_size=3, padding= 2, stride=1)\n",
    "out = mo(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5060cee6-61eb-4dda-99c8-f8b87466ab74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 8, 8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbeb0ab0-7ec2-4629-803d-71f4dcffad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo2 = nn.Conv2d(12, 12, kernel_size=2, padding=0, stride=2)\n",
    "out2 = mo2(out)\n",
    "out2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64f33328-ddda-4899-beb6-6c0f7014245a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4835,  0.4639, -0.8512,  0.2068,  0.9329, -0.8715],\n",
       "         [ 0.8920,  0.4750,  0.5990, -0.7862, -2.8954, -0.7443],\n",
       "         [ 0.1210, -0.5190, -1.8336,  0.1794,  0.3034, -0.2393],\n",
       "         [-0.2965, -0.1611, -0.9751,  0.6369, -0.3183,  1.5468],\n",
       "         [ 0.5050,  1.4100, -0.8356, -0.2733, -0.6300, -0.9070],\n",
       "         [-0.7207,  0.1379, -0.0037,  0.4786, -0.7435, -0.1926]],\n",
       "\n",
       "        [[-0.7502,  0.6813, -0.7140, -0.4782,  0.7707,  0.1371],\n",
       "         [ 0.9053,  0.5319,  0.2239,  0.2194,  0.1502, -0.3994],\n",
       "         [ 0.0880, -1.2023, -0.1225,  0.8335,  1.0350,  1.1204],\n",
       "         [-0.7130, -0.6812,  0.4312, -1.4486,  1.2049,  0.5230],\n",
       "         [-0.2636,  0.6256,  0.7850, -0.1461,  0.3844, -1.5728],\n",
       "         [-1.6214, -1.1041, -0.2136, -0.0750, -1.4920, -0.6170]],\n",
       "\n",
       "        [[ 0.1096,  0.5267,  0.5914, -0.3038, -0.9623, -0.1392],\n",
       "         [ 0.6680, -0.9267, -0.2822,  0.6497, -0.0046,  0.4815],\n",
       "         [ 0.9842,  0.8898,  0.0829, -1.7288, -0.4284, -0.1930],\n",
       "         [ 0.4166,  0.4518,  0.2777, -1.6566, -0.2889,  1.1097],\n",
       "         [ 1.8353,  0.5785, -0.0359,  1.3196, -1.3591,  0.1031],\n",
       "         [ 1.1010,  0.5736,  1.6218, -0.7671,  0.4326, -0.3794]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[2][1][0]*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a1e0fcf-5237-4dcd-9316-f5306b075f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5916,  0.5676, -1.0415,  0.2531,  1.1415, -1.0663],\n",
       "         [ 1.0914,  0.5812,  0.7329, -0.9620, -3.5427, -0.9107],\n",
       "         [ 0.1481, -0.6351, -2.2436,  0.2195,  0.3712, -0.2928],\n",
       "         [-0.3627, -0.1971, -1.1930,  0.7793, -0.3895,  1.8926],\n",
       "         [ 0.6179,  1.7252, -1.0225, -0.3343, -0.7708, -1.1098],\n",
       "         [-0.8818,  0.1688, -0.0045,  0.5856, -0.9097, -0.2356]],\n",
       "\n",
       "        [[-0.9179,  0.8336, -0.8736, -0.5851,  0.9430,  0.1678],\n",
       "         [ 1.1078,  0.6509,  0.2739,  0.2685,  0.1837, -0.4887],\n",
       "         [ 0.1076, -1.4711, -0.1499,  1.0199,  1.2663,  1.3709],\n",
       "         [-0.8724, -0.8335,  0.5277, -1.7724,  1.4742,  0.6399],\n",
       "         [-0.3226,  0.7655,  0.9605, -0.1787,  0.4703, -1.9245],\n",
       "         [-1.9839, -1.3509, -0.2614, -0.0918, -1.8255, -0.7549]],\n",
       "\n",
       "        [[ 0.1341,  0.6445,  0.7236, -0.3718, -1.1775, -0.1703],\n",
       "         [ 0.8173, -1.1339, -0.3453,  0.7949, -0.0057,  0.5891],\n",
       "         [ 1.2043,  1.0888,  0.1014, -2.1153, -0.5242, -0.2361],\n",
       "         [ 0.5098,  0.5529,  0.3398, -2.0270, -0.3535,  1.3578],\n",
       "         [ 2.2456,  0.7079, -0.0439,  1.6147, -1.6629,  0.1261],\n",
       "         [ 1.3471,  0.7019,  1.9844, -0.9387,  0.5293, -0.4642]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea1fdb06-50e2-42ab-a832-f164e18fed02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8173)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[2][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5de15587-116a-4206-9f00-7e3614abc9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1650,  0.0029], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(3, 2)\n",
    "m = []\n",
    "for i in range(3):\n",
    "    m.append((float(n[i].flatten().mean())))\n",
    "m = torch.Tensor(m)\n",
    "a = fc(m)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81d8b1e6-8664-42dc-93e6-173ae09dd2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0221, -0.1064, -0.1194,  0.0613,  0.1943,  0.0281],\n",
       "        [-0.1349,  0.1871,  0.0570, -0.1312,  0.0009, -0.0972],\n",
       "        [-0.1987, -0.1797, -0.0167,  0.3490,  0.0865,  0.0390],\n",
       "        [-0.0841, -0.0912, -0.0561,  0.3345,  0.0583, -0.2240],\n",
       "        [-0.3705, -0.1168,  0.0073, -0.2664,  0.2744, -0.0208],\n",
       "        [-0.2223, -0.1158, -0.3274,  0.1549, -0.0873,  0.0766]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]*n[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9bff5881-c427-4dd7-8724-f42719757237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 6])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [n, n]\n",
    "s = sum(l)\n",
    "s.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3c47997e-af3f-4915-b378-2da1e70b3ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5916,  0.5676, -1.0415,  0.2531,  1.1415, -1.0663],\n",
       "         [ 1.0914,  0.5812,  0.7329, -0.9620, -3.5427, -0.9107],\n",
       "         [ 0.1481, -0.6351, -2.2436,  0.2195,  0.3712, -0.2928],\n",
       "         [-0.3627, -0.1971, -1.1930,  0.7793, -0.3895,  1.8926],\n",
       "         [ 0.6179,  1.7252, -1.0225, -0.3343, -0.7708, -1.1098],\n",
       "         [-0.8818,  0.1688, -0.0045,  0.5856, -0.9097, -0.2356]],\n",
       "\n",
       "        [[-0.9179,  0.8336, -0.8736, -0.5851,  0.9430,  0.1678],\n",
       "         [ 1.1078,  0.6509,  0.2739,  0.2685,  0.1837, -0.4887],\n",
       "         [ 0.1076, -1.4711, -0.1499,  1.0199,  1.2663,  1.3709],\n",
       "         [-0.8724, -0.8335,  0.5277, -1.7724,  1.4742,  0.6399],\n",
       "         [-0.3226,  0.7655,  0.9605, -0.1787,  0.4703, -1.9245],\n",
       "         [-1.9839, -1.3509, -0.2614, -0.0918, -1.8255, -0.7549]],\n",
       "\n",
       "        [[ 0.1341,  0.6445,  0.7236, -0.3718, -1.1775, -0.1703],\n",
       "         [ 0.8173, -1.1339, -0.3453,  0.7949, -0.0057,  0.5891],\n",
       "         [ 1.2043,  1.0888,  0.1014, -2.1153, -0.5242, -0.2361],\n",
       "         [ 0.5098,  0.5529,  0.3398, -2.0270, -0.3535,  1.3578],\n",
       "         [ 2.2456,  0.7079, -0.0439,  1.6147, -1.6629,  0.1261],\n",
       "         [ 1.3471,  0.7019,  1.9844, -0.9387,  0.5293, -0.4642]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4927ee48-0ae2-4e5f-a045-d6a2127e0cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.5916,  0.5676, -1.0415,  0.2531,  1.1415, -1.0663],\n",
       "          [ 1.0914,  0.5812,  0.7329, -0.9620, -3.5427, -0.9107],\n",
       "          [ 0.1481, -0.6351, -2.2436,  0.2195,  0.3712, -0.2928],\n",
       "          [-0.3627, -0.1971, -1.1930,  0.7793, -0.3895,  1.8926],\n",
       "          [ 0.6179,  1.7252, -1.0225, -0.3343, -0.7708, -1.1098],\n",
       "          [-0.8818,  0.1688, -0.0045,  0.5856, -0.9097, -0.2356]],\n",
       " \n",
       "         [[-0.9179,  0.8336, -0.8736, -0.5851,  0.9430,  0.1678],\n",
       "          [ 1.1078,  0.6509,  0.2739,  0.2685,  0.1837, -0.4887],\n",
       "          [ 0.1076, -1.4711, -0.1499,  1.0199,  1.2663,  1.3709],\n",
       "          [-0.8724, -0.8335,  0.5277, -1.7724,  1.4742,  0.6399],\n",
       "          [-0.3226,  0.7655,  0.9605, -0.1787,  0.4703, -1.9245],\n",
       "          [-1.9839, -1.3509, -0.2614, -0.0918, -1.8255, -0.7549]],\n",
       " \n",
       "         [[ 0.1341,  0.6445,  0.7236, -0.3718, -1.1775, -0.1703],\n",
       "          [ 0.8173, -1.1339, -0.3453,  0.7949, -0.0057,  0.5891],\n",
       "          [ 1.2043,  1.0888,  0.1014, -2.1153, -0.5242, -0.2361],\n",
       "          [ 0.5098,  0.5529,  0.3398, -2.0270, -0.3535,  1.3578],\n",
       "          [ 2.2456,  0.7079, -0.0439,  1.6147, -1.6629,  0.1261],\n",
       "          [ 1.3471,  0.7019,  1.9844, -0.9387,  0.5293, -0.4642]]])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = []\n",
    "s.append(0)\n",
    "s[0] = n\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d61c3f11-5332-4c42-8a52-afe39b0a9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test1(nn.Module):\n",
    "    # Creating Intermediate Blocks\n",
    "    # the length of param indicates the number of intermediate blocks\n",
    "    # each parameter is then inside the param for convolutional layers\n",
    "    def __init__(self, in_channels, out_channels, c, layers, paddings, strides, kernels):\n",
    "        super(Test1, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        master_model = []\n",
    "        self.c = c\n",
    "        self.layers = layers\n",
    "        for i in range(c):\n",
    "            convs = nn.ModuleList()\n",
    "            for j in range(layers[i]):\n",
    "                convs.append(nn.Conv2d(in_channels[i][j], out_channels[i][j], kernel_size=kernels[i][j],stride= strides[i][j], padding= paddings[i][j]))\n",
    "            master_model.append(convs)\n",
    "        \n",
    "        self.model = master_model\n",
    "        # the fully-connected layer turning m to a to calculate the weights of convolutional layer in the final equation the output should be the same value as the number of concolutional layers\n",
    "        self.fc = nn.Linear(in_channels[0][0], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m = []\n",
    "        for i in range(x.size()[0]):\n",
    "            m.append((float(x[i].flatten().mean())))\n",
    "        m = torch.Tensor(m)\n",
    "        a = self.fc(m)\n",
    "        # creating the convolutional neurons in the layer of the block\n",
    "        x = self.relu(x)\n",
    "        model = self.model\n",
    "        out_list = []\n",
    "        for i in range(self.c):\n",
    "            s.append(0)\n",
    "            mod = mo[i]\n",
    "            out = x\n",
    "            for model in mod:\n",
    "                out = model(out)\n",
    "            print(out.size())\n",
    "            out_list[i] = out\n",
    " \n",
    "        return sum(out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "97a19c9d-0bc6-4a94-87b3-b1358d381fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 4, 4])\n",
      "torch.Size([12, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "t1 = Test1(in_channels=[[3,12],[3,6]], out_channels=[[12,12],[6,12]], c=2, layers=[2,2], paddings=[[2,0],[0,0]], strides=[[1,2],[1,1]], kernels=[[3,2],[3,1]])\n",
    "out= t1(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c9d52343-2de8-4b57-93e9-5b6006b245bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d583495e-f5a8-462a-bf74-8a887c2e6b33",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ModuleList.append() missing 1 required positional argument: 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m strides\u001b[38;5;241m=\u001b[39m [[[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m]], [[\u001b[38;5;241m1\u001b[39m]]]\n\u001b[1;32m      8\u001b[0m kernels \u001b[38;5;241m=\u001b[39m [[[\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m],[\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m]], [[\u001b[38;5;241m2\u001b[39m]]]\n\u001b[0;32m----> 9\u001b[0m t2 \u001b[38;5;241m=\u001b[39m \u001b[43mFinalModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_block\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpaddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkernels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_channels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m out2 \u001b[38;5;241m=\u001b[39m t2(n)\n",
      "Cell \u001b[0;32mIn[132], line 9\u001b[0m, in \u001b[0;36mFinalModel.__init__\u001b[0;34m(self, num_block, c, layers, in_channels, out_channels, kernels, paddings, strides)\u001b[0m\n\u001b[1;32m      7\u001b[0m blocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_block):\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mblocks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBlockGen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_channels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m blocks\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(in_channels[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: ModuleList.append() missing 1 required positional argument: 'module'"
     ]
    }
   ],
   "source": [
    "num_blocks=2\n",
    "c = [2,1]\n",
    "in_channels = [[[3,12],[3,6]],[[12]]]\n",
    "out_channels=[[[12,12],[6,12]], [[24]]]\n",
    "layers = [[2,2], [2]]\n",
    "paddings = [[[2,0],[0,0]],[[0]]]\n",
    "strides= [[[1,2],[1,1]], [[1]]]\n",
    "kernels = [[[3,2],[3,1]], [[2]]]\n",
    "t2 = FinalModel(num_block=2, c = c, layers = layers, paddings = paddings, strides = strides, kernels= kernels, in_channels=in_channels, out_channels=out_channels)\n",
    "out2 = t2(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2400f73d-52c1-4f29-80b2-24753ff2b268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4, 4])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39d05d96-5825-4d8f-af72-971ca5cdff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.8419e-02,  1.6770e-01,  3.1307e-01,  7.2142e-01],\n",
       "         [ 3.3566e-01,  3.9943e-01,  3.3564e-01,  5.6603e-01],\n",
       "         [ 3.6193e-01,  3.2218e-01,  3.7127e-01, -6.9696e-02],\n",
       "         [ 5.0027e-01,  2.2803e-01, -3.7562e-01,  1.4719e-01]],\n",
       "\n",
       "        [[-1.8553e-01, -4.0123e-01, -2.9772e-01,  2.7814e-01],\n",
       "         [-8.0064e-02, -2.6071e-01, -1.5985e-01,  1.0840e-01],\n",
       "         [-2.4959e-01, -2.0578e-01, -3.0418e-01,  6.0164e-02],\n",
       "         [-3.8600e-01, -2.1963e-01, -2.9663e-01, -1.3248e-01]],\n",
       "\n",
       "        [[ 5.4785e-01,  6.0923e-01,  3.0646e-01, -3.8727e-02],\n",
       "         [ 8.1283e-02,  7.5408e-01,  8.9265e-01,  1.0795e+00],\n",
       "         [ 5.9987e-01,  2.6477e-01,  2.0524e-01,  1.2205e+00],\n",
       "         [ 3.9801e-01, -2.1707e-01,  3.4907e-01,  1.5826e-01]],\n",
       "\n",
       "        [[ 6.0254e-01,  5.0626e-01,  3.3722e-01,  2.4083e-01],\n",
       "         [ 4.6832e-01,  4.3215e-01,  8.5814e-02,  2.2329e-02],\n",
       "         [ 4.4482e-01,  1.0624e-01,  1.5738e-01,  2.4904e-01],\n",
       "         [ 4.6385e-01,  1.5108e-01,  2.7895e-01,  5.4716e-01]],\n",
       "\n",
       "        [[ 3.8242e-01,  1.8733e-01,  3.5986e-01,  1.9423e-01],\n",
       "         [ 4.8442e-01,  3.3820e-01,  4.6443e-01,  3.0709e-01],\n",
       "         [ 3.1413e-01,  6.7655e-02,  3.5431e-01,  1.9642e-01],\n",
       "         [ 3.3440e-01,  3.9255e-01,  4.5601e-02,  4.1046e-01]],\n",
       "\n",
       "        [[-8.8047e-02,  9.6152e-02,  1.2509e-01,  6.2054e-02],\n",
       "         [-6.6327e-02, -2.8978e-01,  2.9537e-01,  4.8602e-01],\n",
       "         [ 2.1872e-02,  7.1222e-02,  2.0418e-01,  3.0224e-01],\n",
       "         [-4.6234e-01,  1.0390e-01, -1.5382e-01,  2.2361e-01]],\n",
       "\n",
       "        [[ 1.1199e-01,  8.3662e-02,  1.4754e-01,  4.1631e-01],\n",
       "         [ 1.4812e-01,  7.9755e-02, -1.7974e-01,  3.8651e-01],\n",
       "         [ 6.3404e-01,  6.0666e-02, -6.5727e-01, -7.0400e-02],\n",
       "         [ 4.8080e-01,  8.3248e-02,  9.9052e-03, -7.1977e-02]],\n",
       "\n",
       "        [[ 3.4303e-01,  4.1562e-01,  2.1651e-01,  2.3491e-01],\n",
       "         [ 1.2675e-01,  3.6412e-01,  2.7193e-01,  3.0581e-01],\n",
       "         [ 1.4658e-01,  3.1346e-02,  5.2756e-01,  4.3059e-01],\n",
       "         [ 1.1876e-01,  3.1771e-01,  1.8461e-01,  4.8548e-01]],\n",
       "\n",
       "        [[ 4.1288e-01,  2.5264e-01,  5.6243e-01,  5.8885e-01],\n",
       "         [ 6.7168e-01,  2.8493e-01,  1.0857e-01,  5.1170e-01],\n",
       "         [ 9.0426e-01,  1.8263e-01,  2.9134e-01,  6.4020e-02],\n",
       "         [ 5.5176e-01,  3.5197e-01, -2.0213e-05,  3.8220e-01]],\n",
       "\n",
       "        [[-1.7813e-03, -3.5927e-02, -1.4371e-01,  2.2409e-01],\n",
       "         [ 3.5027e-02,  9.8731e-02,  6.7257e-02,  2.6850e-01],\n",
       "         [ 3.5569e-01, -1.8279e-01, -1.0510e-01, -3.0569e-01],\n",
       "         [ 3.4021e-01,  4.1218e-02, -2.4715e-01, -5.0981e-02]],\n",
       "\n",
       "        [[-6.8821e-03, -1.9716e-01,  2.0678e-01,  1.5280e-01],\n",
       "         [ 2.6069e-01,  1.0066e-01,  5.1264e-02, -3.6568e-02],\n",
       "         [ 2.4691e-01, -8.1201e-02,  3.1117e-02, -2.7442e-01],\n",
       "         [ 2.6327e-01,  2.0508e-01,  7.4768e-02,  3.0422e-01]],\n",
       "\n",
       "        [[-3.8125e-01, -1.2716e-01, -3.3472e-01, -2.9474e-01],\n",
       "         [-3.3634e-01, -2.9057e-01, -1.9988e-01, -1.0162e-01],\n",
       "         [-4.6255e-01, -2.3645e-01, -4.9215e-02, -5.7741e-01],\n",
       "         [-3.3381e-01, -1.2243e-01, -4.7114e-01, -3.1630e-01]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54528216-0b1f-4d31-b124-a69502f06341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aead49bf-f489-49a1-ad95-73c425f20715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc = nn.Linear(out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(x)\n",
    "        out1 = self.conv1(out)\n",
    "        out2 = self.conv2(out)\n",
    "        out3 = self.conv3(out)\n",
    "        out4 = self.conv4(out)\n",
    "        out5 = self.conv5(out)\n",
    "        \n",
    "        # Average pooling\n",
    "        avg_pool = x.\n",
    "        avg_pool = avg_pool.view(avg_pool.size(0), -1)\n",
    "        # Weighted average calculation\n",
    "        weights = torch.sigmoid(self.fc(avg_pool))\n",
    "        print(weights.type())\n",
    "        # Weighted sum\n",
    "        weighted_sum = (out1 + out2 + out3 + out4 + out5) * weights.view(-1,1,1,1)\n",
    "        \n",
    "        return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d6a55176-da30-4c42-94df-3637801a3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[[12,12],[6,12]],\n",
    "    [[18, 24], [12, 24]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "88ef4f93-c549-4bef-9c16-f6d69560be32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1][-2][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
