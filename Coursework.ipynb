{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4fca06-f3df-4d3d-8465-c493f7879612",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85307fef-752a-4a8b-86d4-fb6f5d2f3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cd635c-7e1e-453a-8324-c2cf1c1812da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to understand this function for now.\n",
    "def load_data_CIFAR10(batch_size, resize=None):\n",
    "    \"\"\"Download the CIFAR10 dataset and then load it into memory.\"\"\"\n",
    "    trans = [torchvision.transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, torchvision.transforms.Resize(resize))\n",
    "    trans = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=2),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86b1a98-2bd4-4d28-8aa9-b4e8536adb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # Defines the batch size\n",
    "train_iter, test_iter = load_data_CIFAR10(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecba6e7-eb01-4ee4-93c4-9ec60f808e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_iter)) # Requests the first training batch\n",
    "print(X.size()) # 256 images per batch. Each image is represented by a 1 x 28 x 28 tensor (number of channels x height x width). The images are grayscale, so there is a single channel.\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff0d21-e530-4f8e-994a-bde7be049a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockGen(nn.Module):\n",
    "    # Creating Intermediate Blocks\n",
    "    def __init__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aead49bf-f489-49a1-ad95-73c425f20715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc = nn.Linear(out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(x)\n",
    "        out1 = self.conv1(out)\n",
    "        out2 = self.conv2(out)\n",
    "        out3 = self.conv3(out)\n",
    "        out4 = self.conv4(out)\n",
    "        out5 = self.conv5(out)\n",
    "        \n",
    "        # Average pooling\n",
    "        avg_pool = x.\n",
    "        avg_pool = avg_pool.view(avg_pool.size(0), -1)\n",
    "        # Weighted average calculation\n",
    "        weights = torch.sigmoid(self.fc(avg_pool))\n",
    "        print(weights.type())\n",
    "        # Weighted sum\n",
    "        weighted_sum = (out1 + out2 + out3 + out4 + out5) * weights.view(-1,1,1,1)\n",
    "        \n",
    "        return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb6ae26-f43d-424b-915b-f421766d7619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvBlock(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applies Xavier initialization if the `torch.nn.Module` is `torch.nn.Linear` or `torch.nn.Conv2d`\n",
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "num_outputs = 10\n",
    "model = ConvBlock(in_channels=3, out_channels=num_outputs)\n",
    "model.apply(init_weights) # Applies `init_weights` to every `torch.nn.Module` inside `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62987da8-567b-4690-8e9c-2d0a05481ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8fb2b4-1828-4960-81a1-49c84469adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f79f66-bf58-4a62-912a-b4b0931a9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(logits, y):\n",
    "    y_hat = logits.argmax(axis=1) # Finds the column with the highest value for each row of `logits`.\n",
    "    return (y_hat == y).float().sum() # Computes the number of times that `y_hat` and `y` match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440558aa-4038-48a2-9668-ea8b5a882e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metric(model, data_iter, metric):\n",
    "    \"\"\"Compute the average `metric` of the model on a dataset.\"\"\"\n",
    "    c = torch.tensor(0.)\n",
    "    n = torch.tensor(0.)\n",
    "    for X, y in data_iter:\n",
    "        logits = model(X)\n",
    "        c += metric(logits, y)\n",
    "        n += len(y)\n",
    "\n",
    "    return c / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698f82c-1c72-4e07-9305-e07e0c612058",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training accuracy: {evaluate_metric(model, train_iter, correct)}. Testing accuracy: {evaluate_metric(model, test_iter, correct)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49038c73-c646-40fd-a5a8-5297a7885e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc = nn.Linear(out_channels, 10)  # Output size is 10\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = F.relu(self.conv1(x))\n",
    "        out2 = F.relu(self.conv2(out1))\n",
    "        out3 = F.relu(self.conv3(out2))\n",
    "        out4 = F.relu(self.conv4(out3))\n",
    "        out5 = F.relu(self.conv5(out4))\n",
    "        \n",
    "        # Average pooling\n",
    "        avg_pool = F.avg_pool2d(out5, kernel_size=out5.size()[2:])\n",
    "        avg_pool = avg_pool.view(avg_pool.size(0), -1)\n",
    "        \n",
    "        # Weighted average calculation\n",
    "        weights = torch.sigmoid(self.fc(avg_pool))\n",
    "        \n",
    "        # Weighted sum\n",
    "        weighted_sum = (out1 + out2 + out3 + out4 + out5) * weights.view(-1, 10, 1, 1)  # Adjust the shape\n",
    "        \n",
    "        return weighted_sum\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming input image size is 32x32 and 3 channels\n",
    "    input_image = torch.randn(64, 3, 32, 32)\n",
    "    model = ConvBlock(in_channels=3, out_channels=64)\n",
    "    output = model(input_image)\n",
    "    print(\"Output size:\", output.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8eb359-3ad6-4409-911b-70c5701f1861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
