{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4fca06-f3df-4d3d-8465-c493f7879612",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85307fef-752a-4a8b-86d4-fb6f5d2f3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cd635c-7e1e-453a-8324-c2cf1c1812da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to understand this function for now.\n",
    "def load_data_CIFAR10(batch_size, resize=None):\n",
    "    \"\"\"Download the CIFAR10 dataset and then load it into memory.\"\"\"\n",
    "    trans = [torchvision.transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, torchvision.transforms.Resize(resize))\n",
    "    trans = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=2),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86b1a98-2bd4-4d28-8aa9-b4e8536adb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # Defines the batch size\n",
    "train_iter, test_iter = load_data_CIFAR10(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecba6e7-eb01-4ee4-93c4-9ec60f808e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_iter)) # Requests the first training batch\n",
    "print(X.size()) # 256 images per batch. Each image is represented by a 1 x 28 x 28 tensor (number of channels x height x width). The images are grayscale, so there is a single channel.\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aead49bf-f489-49a1-ad95-73c425f20715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc = nn.Linear(out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(x)\n",
    "        out1 = self.conv1(out)\n",
    "        out2 = self.conv2(out)\n",
    "        out3 = self.conv3(out)\n",
    "        out4 = self.conv4(out)\n",
    "        out5 = self.conv5(out)\n",
    "        \n",
    "        # Average pooling\n",
    "        avg_pool = x.\n",
    "        avg_pool = avg_pool.view(avg_pool.size(0), -1)\n",
    "        # Weighted average calculation\n",
    "        weights = torch.sigmoid(self.fc(avg_pool))\n",
    "        print(weights.type())\n",
    "        # Weighted sum\n",
    "        weighted_sum = (out1 + out2 + out3 + out4 + out5) * weights.view(-1,1,1,1)\n",
    "        \n",
    "        return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb6ae26-f43d-424b-915b-f421766d7619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvBlock(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applies Xavier initialization if the `torch.nn.Module` is `torch.nn.Linear` or `torch.nn.Conv2d`\n",
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "num_outputs = 10\n",
    "model = ConvBlock(in_channels=3, out_channels=num_outputs)\n",
    "model.apply(init_weights) # Applies `init_weights` to every `torch.nn.Module` inside `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62987da8-567b-4690-8e9c-2d0a05481ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8fb2b4-1828-4960-81a1-49c84469adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f79f66-bf58-4a62-912a-b4b0931a9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(logits, y):\n",
    "    y_hat = logits.argmax(axis=1) # Finds the column with the highest value for each row of `logits`.\n",
    "    return (y_hat == y).float().sum() # Computes the number of times that `y_hat` and `y` match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440558aa-4038-48a2-9668-ea8b5a882e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metric(model, data_iter, metric):\n",
    "    \"\"\"Compute the average `metric` of the model on a dataset.\"\"\"\n",
    "    c = torch.tensor(0.)\n",
    "    n = torch.tensor(0.)\n",
    "    for X, y in data_iter:\n",
    "        logits = model(X)\n",
    "        c += metric(logits, y)\n",
    "        n += len(y)\n",
    "\n",
    "    return c / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698f82c-1c72-4e07-9305-e07e0c612058",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training accuracy: {evaluate_metric(model, train_iter, correct)}. Testing accuracy: {evaluate_metric(model, test_iter, correct)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45b272-c01e-4e47-8e17-7a7e608f8db5",
   "metadata": {},
   "source": [
    "# Basic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d41057c-f725-494c-bbe4-7b7a831c6e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2500, 1.5000, 2.7500])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "n = torch.Tensor([[[1,2],[2,4]],[[1,1],[2,2]], [[1,4],[2,4]]])\n",
    "m = []\n",
    "for i in range(n.size()[0]):\n",
    "    m.append((float(n[i].flatten().mean())))\n",
    "m = torch.Tensor(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0cd44b9-c7ff-4546-bee4-08ef382df462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(3, 5)\n",
    "    def forward(self, x):\n",
    "        out  = self.fc1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b89bd00-cceb-4b54-8c05-c9145cddca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = Model()\n",
    "out = k(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ff0d21-e530-4f8e-994a-bde7be049a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockGen(nn.Module):\n",
    "    # Creating Intermediate Blocks\n",
    "    # the length of param indicates the number of intermediate blocks\n",
    "    # each parameter is then inside the param for convolutional layers\n",
    "    def __init__(self, param, in_channels, out_channels):\n",
    "        convs = nn.ModuleList(nn.nn.ReLU())\n",
    "        for p in param:\n",
    "            convs = convs.append(nn.Conv2d(in_channels, out_channels, kernel_size=p['kernel_size'],stride= p['stride']))\n",
    "        self.model = convs\n",
    "    def forward(self, x):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for i, l in enumerate(self.linears):\n",
    "            x = self.model(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91b7f49-3c31-42db-9be7-542537e00dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{'L': 3,'kernel_size':3 , 'stride':1, 'padding':0}, {'out':3, 'L': 3,'kernel_size':2 , 'stride':3, 'padding':1}, {'out':2, 'L': 5,'kernel_size':2 , 'stride':1, 'padding':0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46cf72e3-001c-4d4a-8a9a-de0a52949617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'out': 3, 'L': 3, 'kernel_size': 3, 'stride': 1, 'padding': 0}\n",
      "{'out': 4, 'L': 3, 'kernel_size': 2, 'stride': 3, 'padding': 1}\n",
      "{'out': 2, 'L': 5, 'kernel_size': 2, 'stride': 1, 'padding': 0}\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(param):\n",
    "    print(param[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92b36f43-d48d-49b1-b45b-5a30f153f3d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'nn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mBlockGen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36mBlockGen.__init__\u001b[0;34m(self, param, in_channels, out_channels)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, param, in_channels, out_channels):\n\u001b[0;32m----> 6\u001b[0m     convs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mReLU())\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m param:\n\u001b[1;32m      8\u001b[0m         convs \u001b[38;5;241m=\u001b[39m convs\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels, out_channels, kernel_size\u001b[38;5;241m=\u001b[39mp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_size\u001b[39m\u001b[38;5;124m'\u001b[39m],stride\u001b[38;5;241m=\u001b[39m p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstride\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'nn'"
     ]
    }
   ],
   "source": [
    "mod = BlockGen(param=param, in_channels=3, out_channels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a643aa4-6c75-40cd-8f03-4b734488dbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
