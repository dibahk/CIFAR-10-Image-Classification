{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4fca06-f3df-4d3d-8465-c493f7879612",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85307fef-752a-4a8b-86d4-fb6f5d2f3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cd635c-7e1e-453a-8324-c2cf1c1812da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to understand this function for now.\n",
    "def load_data_CIFAR10(batch_size, resize=None):\n",
    "    \"\"\"Download the CIFAR10 dataset and then load it into memory.\"\"\"\n",
    "    trans = [torchvision.transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, torchvision.transforms.Resize(resize))\n",
    "    trans = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=2),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86b1a98-2bd4-4d28-8aa9-b4e8536adb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # Defines the batch size\n",
    "train_iter, test_iter = load_data_CIFAR10(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecba6e7-eb01-4ee4-93c4-9ec60f808e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_iter)) # Requests the first training batch\n",
    "print(X.size()) # 256 images per batch. Each image is represented by a 1 x 28 x 28 tensor (number of channels x height x width). The images are grayscale, so there is a single channel.\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aead49bf-f489-49a1-ad95-73c425f20715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc = nn.Linear(out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(x)\n",
    "        out1 = self.conv1(out)\n",
    "        out2 = self.conv2(out)\n",
    "        out3 = self.conv3(out)\n",
    "        out4 = self.conv4(out)\n",
    "        out5 = self.conv5(out)\n",
    "        \n",
    "        # Average pooling\n",
    "        avg_pool = x.\n",
    "        avg_pool = avg_pool.view(avg_pool.size(0), -1)\n",
    "        # Weighted average calculation\n",
    "        weights = torch.sigmoid(self.fc(avg_pool))\n",
    "        print(weights.type())\n",
    "        # Weighted sum\n",
    "        weighted_sum = (out1 + out2 + out3 + out4 + out5) * weights.view(-1,1,1,1)\n",
    "        \n",
    "        return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb6ae26-f43d-424b-915b-f421766d7619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvBlock(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applies Xavier initialization if the `torch.nn.Module` is `torch.nn.Linear` or `torch.nn.Conv2d`\n",
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "num_outputs = 10\n",
    "model = ConvBlock(in_channels=3, out_channels=num_outputs)\n",
    "model.apply(init_weights) # Applies `init_weights` to every `torch.nn.Module` inside `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62987da8-567b-4690-8e9c-2d0a05481ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8fb2b4-1828-4960-81a1-49c84469adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f79f66-bf58-4a62-912a-b4b0931a9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(logits, y):\n",
    "    y_hat = logits.argmax(axis=1) # Finds the column with the highest value for each row of `logits`.\n",
    "    return (y_hat == y).float().sum() # Computes the number of times that `y_hat` and `y` match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440558aa-4038-48a2-9668-ea8b5a882e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metric(model, data_iter, metric):\n",
    "    \"\"\"Compute the average `metric` of the model on a dataset.\"\"\"\n",
    "    c = torch.tensor(0.)\n",
    "    n = torch.tensor(0.)\n",
    "    for X, y in data_iter:\n",
    "        logits = model(X)\n",
    "        c += metric(logits, y)\n",
    "        n += len(y)\n",
    "\n",
    "    return c / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698f82c-1c72-4e07-9305-e07e0c612058",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training accuracy: {evaluate_metric(model, train_iter, correct)}. Testing accuracy: {evaluate_metric(model, test_iter, correct)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45b272-c01e-4e47-8e17-7a7e608f8db5",
   "metadata": {},
   "source": [
    "# Basic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4bfbd-ceea-4b51-97fa-09d673d615d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d41057c-f725-494c-bbe4-7b7a831c6e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.1000, 3.4000, 5.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "n = torch.Tensor([[[1,2,6,4,7],[2,4,3,5,7]],[[1,1,4,3,2],[2,2,7,5,7]], [[1,4,8,4,7],[2,4,8,5,7]]])\n",
    "m = []\n",
    "for i in range(n.size()[0]):\n",
    "    m.append((float(n[i].flatten().mean())))\n",
    "m = torch.Tensor(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0cd44b9-c7ff-4546-bee4-08ef382df462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(3, 5)\n",
    "    def forward(self, x):\n",
    "        out  = self.fc1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b89bd00-cceb-4b54-8c05-c9145cddca14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m k \u001b[38;5;241m=\u001b[39m Model()\n\u001b[0;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m k(\u001b[43mm\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "k = Model()\n",
    "out = k(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ff0d21-e530-4f8e-994a-bde7be049a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockGen(nn.Module):\n",
    "    # Creating Intermediate Blocks\n",
    "    # the length of param indicates the number of intermediate blocks\n",
    "    # each parameter is then inside the param for convolutional layers\n",
    "    def __init__(self, in_channels, out_channels, c, layers, paddings, strides, kernels):\n",
    "        super(BlockGen, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        convolutions = nn.ModuleList\n",
    "        \n",
    "        for i in c:\n",
    "            convs = nn.ModuleList()\n",
    "            for j in range(layers[i]):\n",
    "                convs.append(nn.Conv2d(in_channels[i][j], out_channels[i][j], kernel_size=kernels[i][j],stride= strides[i][j], padding= paddings[i][j]))\n",
    "            covolutions.append(convs)\n",
    "        self.model = convolutions\n",
    "        # the fully-connected layer turning m to a to calculate the weights of convolutional layer in the final equation\n",
    "        self.a = nn.Linear(in_channels, len(param))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m = []\n",
    "        for i in range(x.size()[0]):\n",
    "            m.append((float(x[i].flatten().mean())))\n",
    "        m = torch.Tensor(m)\n",
    "        weights = self.a(m)\n",
    "        # creating the convolutional neurons in the layer of the block\n",
    "        x = self.relu(x)\n",
    "        layer = []\n",
    "        for conv in self.model:\n",
    "            layer.append(conv(x))\n",
    "        return layer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d49ca46-e833-480e-8901-7dd53fe67112",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2093479193.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    class OutBlock:\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class OutBlock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f91b7f49-3c31-42db-9be7-542537e00dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{'L': 3,'kernel_size':1 , 'stride':1, 'padding':0}, {'out':3, 'L': 3,'kernel_size':2 , 'stride':3, 'padding':1}, {'out':2, 'L': 5,'kernel_size':2 , 'stride':1, 'padding':0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "46cf72e3-001c-4d4a-8a9a-de0a52949617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L': 3, 'kernel_size': 1, 'stride': 1, 'padding': 0}\n",
      "{'out': 3, 'L': 3, 'kernel_size': 2, 'stride': 3, 'padding': 1}\n",
      "{'out': 2, 'L': 5, 'kernel_size': 2, 'stride': 1, 'padding': 0}\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(param):\n",
    "    print(param[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e94b33b-0144-4ed5-b58d-b0cbab403175",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmod\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mod' is not defined"
     ]
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c519e-7681-4f72-9546-f4b62aaf11d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b36f43-d48d-49b1-b45b-5a30f153f3d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (4252390199.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    mod = Blo\"ckGen(param=param, in_channels=3, out_channels=10)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "mod = Blo\"ckGen(param=param, in_channels=3, out_channels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7a643aa4-6c75-40cd-8f03-4b734488dbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mod(n)\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ecac8036-a2a0-4d43-a700-1296cd511396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4177ff3a-1fe7-4482-9f5b-3cbb372968dc",
   "metadata": {},
   "source": [
    "## Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b41e7467-ee60-42c8-bc44-875ffc24eb2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5916,  0.5676, -1.0415,  0.2531,  1.1415, -1.0663],\n",
       "         [ 1.0914,  0.5812,  0.7329, -0.9620, -3.5427, -0.9107],\n",
       "         [ 0.1481, -0.6351, -2.2436,  0.2195,  0.3712, -0.2928],\n",
       "         [-0.3627, -0.1971, -1.1930,  0.7793, -0.3895,  1.8926],\n",
       "         [ 0.6179,  1.7252, -1.0225, -0.3343, -0.7708, -1.1098],\n",
       "         [-0.8818,  0.1688, -0.0045,  0.5856, -0.9097, -0.2356]],\n",
       "\n",
       "        [[-0.9179,  0.8336, -0.8736, -0.5851,  0.9430,  0.1678],\n",
       "         [ 1.1078,  0.6509,  0.2739,  0.2685,  0.1837, -0.4887],\n",
       "         [ 0.1076, -1.4711, -0.1499,  1.0199,  1.2663,  1.3709],\n",
       "         [-0.8724, -0.8335,  0.5277, -1.7724,  1.4742,  0.6399],\n",
       "         [-0.3226,  0.7655,  0.9605, -0.1787,  0.4703, -1.9245],\n",
       "         [-1.9839, -1.3509, -0.2614, -0.0918, -1.8255, -0.7549]],\n",
       "\n",
       "        [[ 0.1341,  0.6445,  0.7236, -0.3718, -1.1775, -0.1703],\n",
       "         [ 0.8173, -1.1339, -0.3453,  0.7949, -0.0057,  0.5891],\n",
       "         [ 1.2043,  1.0888,  0.1014, -2.1153, -0.5242, -0.2361],\n",
       "         [ 0.5098,  0.5529,  0.3398, -2.0270, -0.3535,  1.3578],\n",
       "         [ 2.2456,  0.7079, -0.0439,  1.6147, -1.6629,  0.1261],\n",
       "         [ 1.3471,  0.7019,  1.9844, -0.9387,  0.5293, -0.4642]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = torch.randn(3,6,6)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a096265e-0a6d-4579-b472-dae3894896ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = nn.Conv2d(3, 12, kernel_size=3, padding= 2, stride=1)\n",
    "out = mo(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5060cee6-61eb-4dda-99c8-f8b87466ab74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 8, 8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbeb0ab0-7ec2-4629-803d-71f4dcffad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo2 = nn.Conv2d(12, 12, kernel_size=2, padding=0, stride=2)\n",
    "out2 = mo2(out)\n",
    "out2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64f33328-ddda-4899-beb6-6c0f7014245a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4835,  0.4639, -0.8512,  0.2068,  0.9329, -0.8715],\n",
       "         [ 0.8920,  0.4750,  0.5990, -0.7862, -2.8954, -0.7443],\n",
       "         [ 0.1210, -0.5190, -1.8336,  0.1794,  0.3034, -0.2393],\n",
       "         [-0.2965, -0.1611, -0.9751,  0.6369, -0.3183,  1.5468],\n",
       "         [ 0.5050,  1.4100, -0.8356, -0.2733, -0.6300, -0.9070],\n",
       "         [-0.7207,  0.1379, -0.0037,  0.4786, -0.7435, -0.1926]],\n",
       "\n",
       "        [[-0.7502,  0.6813, -0.7140, -0.4782,  0.7707,  0.1371],\n",
       "         [ 0.9053,  0.5319,  0.2239,  0.2194,  0.1502, -0.3994],\n",
       "         [ 0.0880, -1.2023, -0.1225,  0.8335,  1.0350,  1.1204],\n",
       "         [-0.7130, -0.6812,  0.4312, -1.4486,  1.2049,  0.5230],\n",
       "         [-0.2636,  0.6256,  0.7850, -0.1461,  0.3844, -1.5728],\n",
       "         [-1.6214, -1.1041, -0.2136, -0.0750, -1.4920, -0.6170]],\n",
       "\n",
       "        [[ 0.1096,  0.5267,  0.5914, -0.3038, -0.9623, -0.1392],\n",
       "         [ 0.6680, -0.9267, -0.2822,  0.6497, -0.0046,  0.4815],\n",
       "         [ 0.9842,  0.8898,  0.0829, -1.7288, -0.4284, -0.1930],\n",
       "         [ 0.4166,  0.4518,  0.2777, -1.6566, -0.2889,  1.1097],\n",
       "         [ 1.8353,  0.5785, -0.0359,  1.3196, -1.3591,  0.1031],\n",
       "         [ 1.1010,  0.5736,  1.6218, -0.7671,  0.4326, -0.3794]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[2][1][0]*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a1e0fcf-5237-4dcd-9316-f5306b075f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5916,  0.5676, -1.0415,  0.2531,  1.1415, -1.0663],\n",
       "         [ 1.0914,  0.5812,  0.7329, -0.9620, -3.5427, -0.9107],\n",
       "         [ 0.1481, -0.6351, -2.2436,  0.2195,  0.3712, -0.2928],\n",
       "         [-0.3627, -0.1971, -1.1930,  0.7793, -0.3895,  1.8926],\n",
       "         [ 0.6179,  1.7252, -1.0225, -0.3343, -0.7708, -1.1098],\n",
       "         [-0.8818,  0.1688, -0.0045,  0.5856, -0.9097, -0.2356]],\n",
       "\n",
       "        [[-0.9179,  0.8336, -0.8736, -0.5851,  0.9430,  0.1678],\n",
       "         [ 1.1078,  0.6509,  0.2739,  0.2685,  0.1837, -0.4887],\n",
       "         [ 0.1076, -1.4711, -0.1499,  1.0199,  1.2663,  1.3709],\n",
       "         [-0.8724, -0.8335,  0.5277, -1.7724,  1.4742,  0.6399],\n",
       "         [-0.3226,  0.7655,  0.9605, -0.1787,  0.4703, -1.9245],\n",
       "         [-1.9839, -1.3509, -0.2614, -0.0918, -1.8255, -0.7549]],\n",
       "\n",
       "        [[ 0.1341,  0.6445,  0.7236, -0.3718, -1.1775, -0.1703],\n",
       "         [ 0.8173, -1.1339, -0.3453,  0.7949, -0.0057,  0.5891],\n",
       "         [ 1.2043,  1.0888,  0.1014, -2.1153, -0.5242, -0.2361],\n",
       "         [ 0.5098,  0.5529,  0.3398, -2.0270, -0.3535,  1.3578],\n",
       "         [ 2.2456,  0.7079, -0.0439,  1.6147, -1.6629,  0.1261],\n",
       "         [ 1.3471,  0.7019,  1.9844, -0.9387,  0.5293, -0.4642]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea1fdb06-50e2-42ab-a832-f164e18fed02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8173)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[2][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5de15587-116a-4206-9f00-7e3614abc9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1650,  0.0029], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(3, 2)\n",
    "m = []\n",
    "for i in range(3):\n",
    "    m.append((float(n[i].flatten().mean())))\n",
    "m = torch.Tensor(m)\n",
    "a = fc(m)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81d8b1e6-8664-42dc-93e6-173ae09dd2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0221, -0.1064, -0.1194,  0.0613,  0.1943,  0.0281],\n",
       "        [-0.1349,  0.1871,  0.0570, -0.1312,  0.0009, -0.0972],\n",
       "        [-0.1987, -0.1797, -0.0167,  0.3490,  0.0865,  0.0390],\n",
       "        [-0.0841, -0.0912, -0.0561,  0.3345,  0.0583, -0.2240],\n",
       "        [-0.3705, -0.1168,  0.0073, -0.2664,  0.2744, -0.0208],\n",
       "        [-0.2223, -0.1158, -0.3274,  0.1549, -0.0873,  0.0766]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]*n[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9bff5881-c427-4dd7-8724-f42719757237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 6])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [n, n]\n",
    "s = sum(l)\n",
    "s.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3c47997e-af3f-4915-b378-2da1e70b3ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5916,  0.5676, -1.0415,  0.2531,  1.1415, -1.0663],\n",
       "         [ 1.0914,  0.5812,  0.7329, -0.9620, -3.5427, -0.9107],\n",
       "         [ 0.1481, -0.6351, -2.2436,  0.2195,  0.3712, -0.2928],\n",
       "         [-0.3627, -0.1971, -1.1930,  0.7793, -0.3895,  1.8926],\n",
       "         [ 0.6179,  1.7252, -1.0225, -0.3343, -0.7708, -1.1098],\n",
       "         [-0.8818,  0.1688, -0.0045,  0.5856, -0.9097, -0.2356]],\n",
       "\n",
       "        [[-0.9179,  0.8336, -0.8736, -0.5851,  0.9430,  0.1678],\n",
       "         [ 1.1078,  0.6509,  0.2739,  0.2685,  0.1837, -0.4887],\n",
       "         [ 0.1076, -1.4711, -0.1499,  1.0199,  1.2663,  1.3709],\n",
       "         [-0.8724, -0.8335,  0.5277, -1.7724,  1.4742,  0.6399],\n",
       "         [-0.3226,  0.7655,  0.9605, -0.1787,  0.4703, -1.9245],\n",
       "         [-1.9839, -1.3509, -0.2614, -0.0918, -1.8255, -0.7549]],\n",
       "\n",
       "        [[ 0.1341,  0.6445,  0.7236, -0.3718, -1.1775, -0.1703],\n",
       "         [ 0.8173, -1.1339, -0.3453,  0.7949, -0.0057,  0.5891],\n",
       "         [ 1.2043,  1.0888,  0.1014, -2.1153, -0.5242, -0.2361],\n",
       "         [ 0.5098,  0.5529,  0.3398, -2.0270, -0.3535,  1.3578],\n",
       "         [ 2.2456,  0.7079, -0.0439,  1.6147, -1.6629,  0.1261],\n",
       "         [ 1.3471,  0.7019,  1.9844, -0.9387,  0.5293, -0.4642]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4927ee48-0ae2-4e5f-a045-d6a2127e0cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.5916,  0.5676, -1.0415,  0.2531,  1.1415, -1.0663],\n",
       "          [ 1.0914,  0.5812,  0.7329, -0.9620, -3.5427, -0.9107],\n",
       "          [ 0.1481, -0.6351, -2.2436,  0.2195,  0.3712, -0.2928],\n",
       "          [-0.3627, -0.1971, -1.1930,  0.7793, -0.3895,  1.8926],\n",
       "          [ 0.6179,  1.7252, -1.0225, -0.3343, -0.7708, -1.1098],\n",
       "          [-0.8818,  0.1688, -0.0045,  0.5856, -0.9097, -0.2356]],\n",
       " \n",
       "         [[-0.9179,  0.8336, -0.8736, -0.5851,  0.9430,  0.1678],\n",
       "          [ 1.1078,  0.6509,  0.2739,  0.2685,  0.1837, -0.4887],\n",
       "          [ 0.1076, -1.4711, -0.1499,  1.0199,  1.2663,  1.3709],\n",
       "          [-0.8724, -0.8335,  0.5277, -1.7724,  1.4742,  0.6399],\n",
       "          [-0.3226,  0.7655,  0.9605, -0.1787,  0.4703, -1.9245],\n",
       "          [-1.9839, -1.3509, -0.2614, -0.0918, -1.8255, -0.7549]],\n",
       " \n",
       "         [[ 0.1341,  0.6445,  0.7236, -0.3718, -1.1775, -0.1703],\n",
       "          [ 0.8173, -1.1339, -0.3453,  0.7949, -0.0057,  0.5891],\n",
       "          [ 1.2043,  1.0888,  0.1014, -2.1153, -0.5242, -0.2361],\n",
       "          [ 0.5098,  0.5529,  0.3398, -2.0270, -0.3535,  1.3578],\n",
       "          [ 2.2456,  0.7079, -0.0439,  1.6147, -1.6629,  0.1261],\n",
       "          [ 1.3471,  0.7019,  1.9844, -0.9387,  0.5293, -0.4642]]])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = []\n",
    "s.append(0)\n",
    "s[0] = n\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d61c3f11-5332-4c42-8a52-afe39b0a9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test1(nn.Module):\n",
    "    # Creating Intermediate Blocks\n",
    "    # the length of param indicates the number of intermediate blocks\n",
    "    # each parameter is then inside the param for convolutional layers\n",
    "    def __init__(self, in_channels, out_channels, c, layers, paddings, strides, kernels):\n",
    "        super(Test1, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        master_model = []\n",
    "        self.c = c\n",
    "        self.layers = layers\n",
    "        for i in range(c):\n",
    "            convs = nn.ModuleList()\n",
    "            for j in range(layers[i]):\n",
    "                convs.append(nn.Conv2d(in_channels[i][j], out_channels[i][j], kernel_size=kernels[i][j],stride= strides[i][j], padding= paddings[i][j]))\n",
    "            master_model.append(convs)\n",
    "        \n",
    "        self.model = master_model\n",
    "        # the fully-connected layer turning m to a to calculate the weights of convolutional layer in the final equation the output should be the same value as the number of concolutional layers\n",
    "        self.fc = nn.Linear(in_channels[0][0], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m = []\n",
    "        for i in range(x.size()[0]):\n",
    "            m.append((float(x[i].flatten().mean())))\n",
    "        m = torch.Tensor(m)\n",
    "        a = self.fc(m)\n",
    "        # creating the convolutional neurons in the layer of the block\n",
    "        x = self.relu(x)\n",
    "        mo = self.model\n",
    "        s = []\n",
    "        for i in range(self.c):\n",
    "            s.append(0)\n",
    "            mod = mo[i]\n",
    "            out = x\n",
    "            for model in mod:\n",
    "                out = model(out)\n",
    "            print(out.size())\n",
    "            s[i] = out\n",
    "            \n",
    "        \n",
    "        # for i in range(self.c):\n",
    "        #     s.append(0)\n",
    "        #     out = x\n",
    "        #     for j in range(self.layers):\n",
    "        #         out = self.model(out)\n",
    "        #     s[i] = out\n",
    "        # for i in range(self.c):\n",
    "        #     s.append(convolutions[i]*a[i])    \n",
    "        return sum(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "97a19c9d-0bc6-4a94-87b3-b1358d381fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 4, 4])\n",
      "torch.Size([12, 7, 7])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (7) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t1 \u001b[38;5;241m=\u001b[39m Test1(in_channels\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m12\u001b[39m],[\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m6\u001b[39m]], out_channels\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m12\u001b[39m],[\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m12\u001b[39m]], c\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m], paddings\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m],[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m]], strides\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m]], kernels\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m],[\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m]])\n\u001b[0;32m----> 2\u001b[0m out\u001b[38;5;241m=\u001b[39m \u001b[43mt1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[110], line 49\u001b[0m, in \u001b[0;36mTest1.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     s[i] \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# for i in range(self.c):\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#     s.append(0)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#     out = x\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# for i in range(self.c):\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#     s.append(convolutions[i]*a[i])    \u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(s)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (7) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "t1 = Test1(in_channels=[[3,12],[3,6]], out_channels=[[12,12],[6,12]], c=2, layers=[2,2], paddings=[[2,0],[0,2]], strides=[[1,2],[1,1]], kernels=[[3,2],[3,2]])\n",
    "out= t1(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2400f73d-52c1-4f29-80b2-24753ff2b268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4, 4])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d05d96-5825-4d8f-af72-971ca5cdff20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54528216-0b1f-4d31-b124-a69502f06341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
