{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fd4fca06-f3df-4d3d-8465-c493f7879612",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd4fca06-f3df-4d3d-8465-c493f7879612",
        "outputId": "ecc2e54f-1d8e-441b-dcf7-e51fa8cf942e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using {device}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "85307fef-752a-4a8b-86d4-fb6f5d2f3e25",
      "metadata": {
        "id": "85307fef-752a-4a8b-86d4-fb6f5d2f3e25"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b3f2a69",
      "metadata": {},
      "source": [
        "# Data Loading and pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "22cd635c-7e1e-453a-8324-c2cf1c1812da",
      "metadata": {
        "id": "22cd635c-7e1e-453a-8324-c2cf1c1812da"
      },
      "outputs": [],
      "source": [
        "# You don't need to understand this function for now.\n",
        "def load_data_CIFAR10(batch_size, resize=None):\n",
        "    \"\"\"Download the CIFAR10 dataset and then load it into memory.\"\"\"\n",
        "    train_trans = [\n",
        "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "        torchvision.transforms.RandomCrop(32, padding=4),\n",
        "        torchvision.transforms.RandomRotation(degrees=4),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225])\n",
        "        ]\n",
        "    if resize:\n",
        "        trans.insert(0, torchvision.transforms.Resize(resize))\n",
        "    train_trans = torchvision.transforms.Compose(train_trans)\n",
        "    # the values for mean and std are based on ImageNet common choice\n",
        "    test_trans = [\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        "    test_trans = torchvision.transforms.Compose(test_trans)\n",
        "    mnist_train = torchvision.datasets.CIFAR10(\n",
        "        root=\"./data\", train=True, transform=train_trans, download=True)\n",
        "    mnist_test = torchvision.datasets.CIFAR10(\n",
        "        root=\"./data\", train=False, transform=test_trans, download=True)\n",
        "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
        "                            num_workers=2),\n",
        "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
        "                            num_workers=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f86b1a98-2bd4-4d28-8aa9-b4e8536adb9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f86b1a98-2bd4-4d28-8aa9-b4e8536adb9c",
        "outputId": "1be0d880-cb3b-4733-d0d4-4dd489dfbcdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128 # Defines the batch size\n",
        "train_iter, test_iter = load_data_CIFAR10(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0ecba6e7-eb01-4ee4-93c4-9ec60f808e52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ecba6e7-eb01-4ee4-93c4-9ec60f808e52",
        "outputId": "8e73182f-10de-4f8d-b6ef-bf876ffa0ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "X, y = next(iter(train_iter)) # Requests the first training batch\n",
        "print(X.size()) # 256 images per batch. Each image is represented by a 1 x 28 x 28 tensor (number of channels x height x width). The images are grayscale, so there is a single channel.\n",
        "print(y.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a0f4afa-cb66-47cc-83ea-31a3467ce3b8",
      "metadata": {
        "id": "2a0f4afa-cb66-47cc-83ea-31a3467ce3b8"
      },
      "source": [
        "## Intermediate Block Generator\n",
        "\n",
        "for creating each intermediate block a class has been definied. This class get the number of convolutional layers, and its layers and parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cf1cff80",
      "metadata": {},
      "outputs": [],
      "source": [
        "class BlockGen(nn.Module):\n",
        "    # Creating Intermediate Blocks\n",
        "    # the length of param indicates the number of intermediate blocks\n",
        "    # each parameter is then inside the param for convolutional layers\n",
        "    def __init__(self, in_channels, out_channels, kernels, c):\n",
        "        super(BlockGen, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        convs = nn.ModuleList()\n",
        "        for i in range(c):\n",
        "            \n",
        "            convs.append(nn.Conv2d(in_channels, out_channels, kernel_size=kernels[i], padding= 'same'))\n",
        "\n",
        "        self.model = convs\n",
        "        # the fully-connected layer turning m to a to calculate the weights of convolutional layer in the final equation the output should be the same value as the number of concolutional layers\n",
        "        self.fc = nn.Linear(in_channels, c)\n",
        "        self.batchnorm2d = nn.BatchNorm2d(out_channels)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        m = torch.mean(torch.flatten(x, 2), dim=2)\n",
        "        a = self.fc(m)\n",
        "        \n",
        "        model = self.model\n",
        "        out_list = []\n",
        "        for i, mod in enumerate(model):\n",
        "            weight = a[:, i].unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
        "            out = mod(x)\n",
        "            out_list.append(weight * self.relu(out))\n",
        "\n",
        "        output = torch.sum(torch.stack(out_list), dim=0)\n",
        "        return self.batchnorm2d(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83ccf04a",
      "metadata": {},
      "source": [
        "# Final Model with the output block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "406ed366-1730-4f9f-a495-32f60fbb0d3b",
      "metadata": {
        "id": "406ed366-1730-4f9f-a495-32f60fbb0d3b"
      },
      "outputs": [],
      "source": [
        "class FinalModel(nn.Module):\n",
        "    # Creating Intermediate Blocks\n",
        "    # the length of param indicates the number of intermediate blocks\n",
        "    # each parameter is then inside the param for convolutional layers\n",
        "    def __init__(self, num_block, c, in_channels, out_channels, kernels):\n",
        "        super(FinalModel, self).__init__()\n",
        "        blocks = nn.Sequential()\n",
        "        for i in range(num_block):\n",
        "            blocks.append(BlockGen(in_channels=in_channels[i], out_channels=out_channels[i], kernels=kernels, c=c[i]))\n",
        "            \n",
        "        self.blocks = blocks\n",
        "        self.fc2 = nn.Linear(out_channels[-1], 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # creating the convolutional neurons in the layer of the block\n",
        "        \n",
        "        for model in self.blocks:\n",
        "            x = model(x)\n",
        "\n",
        "        channel_avg = torch.mean(torch.flatten(x, 2), dim=2)\n",
        "        out = self.fc2(channel_avg)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22134dca-2b56-4a68-9171-7d4a1e30bd03",
      "metadata": {
        "id": "22134dca-2b56-4a68-9171-7d4a1e30bd03"
      },
      "source": [
        "## Defining parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bs0zav4E5KyE",
      "metadata": {
        "id": "bs0zav4E5KyE"
      },
      "outputs": [],
      "source": [
        "num_blocks = 4\n",
        "c = [3,3,3,3]\n",
        "kernels = [1,3,5]\n",
        "in_channels = [3,16,32,64]\n",
        "out_channels = [16,32,64,128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8cb6ae26-f43d-424b-915b-f421766d7619",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cb6ae26-f43d-424b-915b-f421766d7619",
        "outputId": "506a131f-5f96-4e85-f884-9106dd1750e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FinalModel(\n",
              "  (blocks): Sequential(\n",
              "    (0): BlockGen(\n",
              "      (relu): ReLU()\n",
              "      (model): ModuleList(\n",
              "        (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
              "        (1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "        (2): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
              "      )\n",
              "      (fc): Linear(in_features=3, out_features=3, bias=True)\n",
              "      (batchnorm2d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (1): BlockGen(\n",
              "      (relu): ReLU()\n",
              "      (model): ModuleList(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
              "        (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "        (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
              "      )\n",
              "      (fc): Linear(in_features=16, out_features=3, bias=True)\n",
              "      (batchnorm2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (2): BlockGen(\n",
              "      (relu): ReLU()\n",
              "      (model): ModuleList(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
              "        (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "        (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
              "      )\n",
              "      (fc): Linear(in_features=32, out_features=3, bias=True)\n",
              "      (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (3): BlockGen(\n",
              "      (relu): ReLU()\n",
              "      (model): ModuleList(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
              "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "        (2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
              "      )\n",
              "      (fc): Linear(in_features=64, out_features=3, bias=True)\n",
              "      (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Applies Xavier initialization if the `torch.nn.Module` is `torch.nn.Linear` or `torch.nn.Conv2d`\n",
        "def init_weights(m):\n",
        "    if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "# num_outputs = 10\n",
        "model = FinalModel(num_block=num_blocks, c = c, in_channels=in_channels, out_channels=out_channels, kernels= kernels).to(device)\n",
        "model.apply(init_weights) # Applies `init_weights` to every `torch.nn.Module` inside `model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "62987da8-567b-4690-8e9c-2d0a05481ce1",
      "metadata": {
        "id": "62987da8-567b-4690-8e9c-2d0a05481ce1"
      },
      "outputs": [],
      "source": [
        "loss = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6a8fb2b4-1828-4960-81a1-49c84469adbb",
      "metadata": {
        "id": "6a8fb2b4-1828-4960-81a1-49c84469adbb"
      },
      "outputs": [],
      "source": [
        "lr = 0.004\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "27f79f66-bf58-4a62-912a-b4b0931a9a70",
      "metadata": {
        "id": "27f79f66-bf58-4a62-912a-b4b0931a9a70"
      },
      "outputs": [],
      "source": [
        "def correct(logits, y):\n",
        "    y_hat = logits.argmax(axis=1) # Finds the column with the highest value for each row of `logits`.\n",
        "    return (y_hat == y).float().sum() # Computes the number of times that `y_hat` and `y` match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "440558aa-4038-48a2-9668-ea8b5a882e6e",
      "metadata": {
        "id": "440558aa-4038-48a2-9668-ea8b5a882e6e"
      },
      "outputs": [],
      "source": [
        "def evaluate_metric(model, data_iter, metric):\n",
        "    \"\"\"Compute the average `metric` of the model on a dataset.\"\"\"\n",
        "    c = torch.tensor(0.).to(device)\n",
        "    n = torch.tensor(0.).to(device)\n",
        "    j = 0\n",
        "    for X, y in data_iter:\n",
        "        X, y = X.to(device), y.to(device) # Moves data to `device`\n",
        "        logits = model(X)\n",
        "        c += metric(logits, y)\n",
        "        n += len(y)\n",
        "    return c*100 / n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6698f82c-1c72-4e07-9305-e07e0c612058",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "6698f82c-1c72-4e07-9305-e07e0c612058",
        "outputId": "962da832-d664-4e1b-daab-23deb8497807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 9.727999687194824. Testing accuracy: 9.859999656677246.\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "print(f'Training accuracy: {evaluate_metric(model, train_iter, correct)}. Testing accuracy: {evaluate_metric(model, test_iter, correct)}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c7b1a07-3d66-4feb-a942-24ff75bf12b2",
      "metadata": {
        "id": "6c7b1a07-3d66-4feb-a942-24ff75bf12b2"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6d1d9280-c122-4640-9b38-49e889393cbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d1d9280-c122-4640-9b38-49e889393cbd",
        "outputId": "7e6a200f-5afb-49e6-fd1c-6662fb8ed1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/100.\n",
            "Training accuracy: 26.365999221801758. Testing accuracy: 27.43000030517578. Duration: 31.529s.\n",
            "\n",
            "Epoch 2/100.\n",
            "Training accuracy: 37.47800064086914. Testing accuracy: 35.560001373291016. Duration: 31.540s.\n",
            "\n",
            "Epoch 3/100.\n",
            "Training accuracy: 52.0620002746582. Testing accuracy: 50.38999938964844. Duration: 31.675s.\n",
            "\n",
            "Epoch 4/100.\n",
            "Training accuracy: 57.577999114990234. Testing accuracy: 55.25. Duration: 31.780s.\n",
            "\n",
            "Epoch 5/100.\n",
            "Training accuracy: 63.970001220703125. Testing accuracy: 63.130001068115234. Duration: 31.737s.\n",
            "\n",
            "Epoch 6/100.\n",
            "Training accuracy: 68.8239974975586. Testing accuracy: 67.63999938964844. Duration: 31.778s.\n",
            "\n",
            "Epoch 7/100.\n",
            "Training accuracy: 70.84200286865234. Testing accuracy: 69.69999694824219. Duration: 31.725s.\n",
            "\n",
            "Epoch 8/100.\n",
            "Training accuracy: 72.98400115966797. Testing accuracy: 71.30000305175781. Duration: 31.726s.\n",
            "\n",
            "Epoch 9/100.\n",
            "Training accuracy: 75.22200012207031. Testing accuracy: 73.41999816894531. Duration: 31.704s.\n",
            "\n",
            "Epoch 10/100.\n",
            "Training accuracy: 76.93800354003906. Testing accuracy: 75.29000091552734. Duration: 31.704s.\n",
            "\n",
            "Epoch 11/100.\n",
            "Training accuracy: 76.99400329589844. Testing accuracy: 75.45999908447266. Duration: 31.699s.\n",
            "\n",
            "Epoch 12/100.\n",
            "Training accuracy: 79.03600311279297. Testing accuracy: 76.9800033569336. Duration: 31.846s.\n",
            "\n",
            "Epoch 13/100.\n",
            "Training accuracy: 80.85600280761719. Testing accuracy: 77.8499984741211. Duration: 31.680s.\n",
            "\n",
            "Epoch 14/100.\n",
            "Training accuracy: 81.88999938964844. Testing accuracy: 78.7699966430664. Duration: 31.756s.\n",
            "\n",
            "Epoch 15/100.\n",
            "Training accuracy: 81.93800354003906. Testing accuracy: 79.25. Duration: 31.729s.\n",
            "\n",
            "Epoch 16/100.\n",
            "Training accuracy: 82.56199645996094. Testing accuracy: 79.08999633789062. Duration: 32.010s.\n",
            "\n",
            "Epoch 17/100.\n",
            "Training accuracy: 83.94999694824219. Testing accuracy: 80.16000366210938. Duration: 31.680s.\n",
            "\n",
            "Epoch 18/100.\n",
            "Training accuracy: 83.98600006103516. Testing accuracy: 80.38999938964844. Duration: 31.652s.\n",
            "\n",
            "Epoch 19/100.\n",
            "Training accuracy: 84.18199920654297. Testing accuracy: 80.44999694824219. Duration: 31.755s.\n",
            "\n",
            "Epoch 20/100.\n",
            "Training accuracy: 84.92400360107422. Testing accuracy: 81.16000366210938. Duration: 31.644s.\n",
            "\n",
            "Epoch 21/100.\n",
            "Training accuracy: 86.08999633789062. Testing accuracy: 82.19000244140625. Duration: 31.644s.\n",
            "\n",
            "Epoch 22/100.\n",
            "Training accuracy: 86.302001953125. Testing accuracy: 81.83000183105469. Duration: 31.630s.\n",
            "\n",
            "Epoch 23/100.\n",
            "Training accuracy: 85.4520034790039. Testing accuracy: 80.7300033569336. Duration: 31.650s.\n",
            "\n",
            "Epoch 24/100.\n",
            "Training accuracy: 87.34600067138672. Testing accuracy: 82.43000030517578. Duration: 31.702s.\n",
            "\n",
            "Epoch 25/100.\n",
            "Training accuracy: 87.19000244140625. Testing accuracy: 81.26000213623047. Duration: 31.576s.\n",
            "\n",
            "Epoch 26/100.\n",
            "Training accuracy: 88.4280014038086. Testing accuracy: 83.05000305175781. Duration: 31.653s.\n",
            "\n",
            "Epoch 27/100.\n",
            "Training accuracy: 89.12000274658203. Testing accuracy: 83.26000213623047. Duration: 32.009s.\n",
            "\n",
            "Epoch 28/100.\n",
            "Training accuracy: 87.23200225830078. Testing accuracy: 81.54000091552734. Duration: 31.653s.\n",
            "\n",
            "Epoch 29/100.\n",
            "Training accuracy: 88.89800262451172. Testing accuracy: 82.80000305175781. Duration: 31.666s.\n",
            "\n",
            "Epoch 30/100.\n",
            "Training accuracy: 89.15399932861328. Testing accuracy: 83.19000244140625. Duration: 31.741s.\n",
            "\n",
            "Epoch 31/100.\n",
            "Training accuracy: 89.41400146484375. Testing accuracy: 82.06999969482422. Duration: 31.978s.\n",
            "\n",
            "Epoch 32/100.\n",
            "Training accuracy: 90.3759994506836. Testing accuracy: 83.80000305175781. Duration: 31.635s.\n",
            "\n",
            "Epoch 33/100.\n",
            "Training accuracy: 89.80799865722656. Testing accuracy: 82.76000213623047. Duration: 31.617s.\n",
            "\n",
            "Epoch 34/100.\n",
            "Training accuracy: 91.05400085449219. Testing accuracy: 83.83999633789062. Duration: 31.640s.\n",
            "\n",
            "Epoch 35/100.\n",
            "Training accuracy: 90.71800231933594. Testing accuracy: 83.79000091552734. Duration: 31.586s.\n",
            "\n",
            "Epoch 36/100.\n",
            "Training accuracy: 90.65599822998047. Testing accuracy: 83.25. Duration: 31.582s.\n",
            "\n",
            "Epoch 37/100.\n",
            "Training accuracy: 91.47799682617188. Testing accuracy: 84.23999786376953. Duration: 31.652s.\n",
            "\n",
            "Epoch 38/100.\n",
            "Training accuracy: 90.9540023803711. Testing accuracy: 84.0999984741211. Duration: 31.620s.\n",
            "\n",
            "Epoch 39/100.\n",
            "Training accuracy: 91.37200164794922. Testing accuracy: 83.33000183105469. Duration: 31.593s.\n",
            "\n",
            "Epoch 40/100.\n",
            "Training accuracy: 91.34400177001953. Testing accuracy: 83.0199966430664. Duration: 31.609s.\n",
            "\n",
            "Epoch 41/100.\n",
            "Training accuracy: 92.35199737548828. Testing accuracy: 83.62999725341797. Duration: 31.701s.\n",
            "\n",
            "Epoch 42/100.\n",
            "Training accuracy: 92.1760025024414. Testing accuracy: 83.73999786376953. Duration: 31.597s.\n",
            "\n",
            "Epoch 43/100.\n",
            "Training accuracy: 91.95600128173828. Testing accuracy: 83.2300033569336. Duration: 31.670s.\n",
            "\n",
            "Epoch 44/100.\n",
            "Training accuracy: 92.3499984741211. Testing accuracy: 83.93000030517578. Duration: 31.786s.\n",
            "\n",
            "Epoch 45/100.\n",
            "Training accuracy: 92.60800170898438. Testing accuracy: 84.05000305175781. Duration: 31.596s.\n",
            "\n",
            "Epoch 46/100.\n",
            "Training accuracy: 93.13999938964844. Testing accuracy: 83.8499984741211. Duration: 31.582s.\n",
            "\n",
            "Epoch 47/100.\n",
            "Training accuracy: 93.28399658203125. Testing accuracy: 84.43000030517578. Duration: 31.589s.\n",
            "\n",
            "Epoch 48/100.\n",
            "Training accuracy: 92.71800231933594. Testing accuracy: 83.2699966430664. Duration: 31.676s.\n",
            "\n",
            "Epoch 49/100.\n",
            "Training accuracy: 93.35199737548828. Testing accuracy: 83.95999908447266. Duration: 31.633s.\n",
            "\n",
            "Epoch 50/100.\n",
            "Training accuracy: 93.71199798583984. Testing accuracy: 83.86000061035156. Duration: 31.565s.\n",
            "\n",
            "Epoch 51/100.\n",
            "Training accuracy: 93.44200134277344. Testing accuracy: 83.37000274658203. Duration: 31.581s.\n",
            "\n",
            "Epoch 52/100.\n",
            "Training accuracy: 94.16200256347656. Testing accuracy: 84.58999633789062. Duration: 31.597s.\n",
            "\n",
            "Epoch 53/100.\n",
            "Training accuracy: 93.96600341796875. Testing accuracy: 84.31999969482422. Duration: 31.567s.\n",
            "\n",
            "Epoch 54/100.\n",
            "Training accuracy: 94.10800170898438. Testing accuracy: 84.37999725341797. Duration: 31.633s.\n",
            "\n",
            "Epoch 55/100.\n",
            "Training accuracy: 94.09600067138672. Testing accuracy: 84.13999938964844. Duration: 31.643s.\n",
            "\n",
            "Epoch 56/100.\n",
            "Training accuracy: 94.39600372314453. Testing accuracy: 84.38999938964844. Duration: 31.661s.\n",
            "\n",
            "Epoch 57/100.\n",
            "Training accuracy: 95.01399993896484. Testing accuracy: 85.05000305175781. Duration: 31.649s.\n",
            "\n",
            "Epoch 58/100.\n",
            "Training accuracy: 91.94599914550781. Testing accuracy: 82.6500015258789. Duration: 31.784s.\n",
            "\n",
            "Epoch 59/100.\n",
            "Training accuracy: 95.02999877929688. Testing accuracy: 84.41999816894531. Duration: 31.988s.\n",
            "\n",
            "Epoch 60/100.\n",
            "Training accuracy: 94.7239990234375. Testing accuracy: 84.4000015258789. Duration: 31.810s.\n",
            "\n",
            "Epoch 61/100.\n",
            "Training accuracy: 94.60399627685547. Testing accuracy: 84.08999633789062. Duration: 31.589s.\n",
            "\n",
            "Epoch 62/100.\n",
            "Training accuracy: 95.28600311279297. Testing accuracy: 84.72000122070312. Duration: 31.652s.\n",
            "\n",
            "Epoch 63/100.\n",
            "Training accuracy: 94.59200286865234. Testing accuracy: 83.88999938964844. Duration: 31.624s.\n",
            "\n",
            "Epoch 64/100.\n",
            "Training accuracy: 95.28399658203125. Testing accuracy: 84.01000213623047. Duration: 31.583s.\n",
            "\n",
            "Epoch 65/100.\n",
            "Training accuracy: 95.54199981689453. Testing accuracy: 84.66000366210938. Duration: 31.583s.\n",
            "\n",
            "Epoch 66/100.\n",
            "Training accuracy: 95.70800018310547. Testing accuracy: 84.2699966430664. Duration: 31.718s.\n",
            "\n",
            "Epoch 67/100.\n",
            "Training accuracy: 94.86199951171875. Testing accuracy: 84.16000366210938. Duration: 31.630s.\n",
            "\n",
            "Epoch 68/100.\n",
            "Training accuracy: 94.54000091552734. Testing accuracy: 83.44000244140625. Duration: 31.846s.\n",
            "\n",
            "Epoch 69/100.\n",
            "Training accuracy: 94.7760009765625. Testing accuracy: 84.52999877929688. Duration: 31.932s.\n",
            "\n",
            "Epoch 70/100.\n",
            "Training accuracy: 95.6500015258789. Testing accuracy: 85.16999816894531. Duration: 32.205s.\n",
            "\n",
            "Epoch 71/100.\n",
            "Training accuracy: 95.69599914550781. Testing accuracy: 84.27999877929688. Duration: 31.989s.\n",
            "\n",
            "Epoch 72/100.\n",
            "Training accuracy: 94.47000122070312. Testing accuracy: 83.48999786376953. Duration: 31.639s.\n",
            "\n",
            "Epoch 73/100.\n",
            "Training accuracy: 96.02200317382812. Testing accuracy: 84.58999633789062. Duration: 31.593s.\n",
            "\n",
            "Epoch 74/100.\n",
            "Training accuracy: 96.10199737548828. Testing accuracy: 85.18000030517578. Duration: 31.800s.\n",
            "\n",
            "Epoch 75/100.\n",
            "Training accuracy: 95.69599914550781. Testing accuracy: 84.20999908447266. Duration: 31.873s.\n",
            "\n",
            "Epoch 76/100.\n",
            "Training accuracy: 95.69999694824219. Testing accuracy: 84.98999786376953. Duration: 31.605s.\n",
            "\n",
            "Epoch 77/100.\n",
            "Training accuracy: 95.51200103759766. Testing accuracy: 84.55000305175781. Duration: 31.598s.\n",
            "\n",
            "Epoch 78/100.\n",
            "Training accuracy: 95.67400360107422. Testing accuracy: 84.26000213623047. Duration: 31.580s.\n",
            "\n",
            "Epoch 79/100.\n",
            "Training accuracy: 95.8239974975586. Testing accuracy: 84.33999633789062. Duration: 31.621s.\n",
            "\n",
            "Epoch 80/100.\n"
          ]
        }
      ],
      "source": [
        "losses = [] # Stores the loss for each training batch\n",
        "train_accs = [] # Stores the training accuracy after each epoch\n",
        "test_accs = [] # Stores the testing accuracy after each epoch\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'\\nEpoch {epoch + 1}/{num_epochs}.')\n",
        "    start_time = time.perf_counter()\n",
        "\n",
        "    model.train() # This is necessary because batch normalization behaves differently between training and evaluation\n",
        "\n",
        "    for X, y in train_iter:\n",
        "        X, y = X.to(device), y.to(device) # Moves data to `device`\n",
        "        logits = model(X) # Computes the logits for the batch of images `X`\n",
        "        l = loss(logits, y) # Computes the loss given the `logits` and the class vector `y`\n",
        "        optimizer.zero_grad() # Zeroes the gradients stored in the model parameters\n",
        "        l.backward() # Computes the gradient of the loss `l` with respect to the model parameters\n",
        "\n",
        "        optimizer.step() # Updates the model parameters based on the gradients stored inside them\n",
        "\n",
        "        losses.append(float(l)) # Stores the loss for this batch\n",
        "\n",
        "    model.eval() # This is necessary because batch normalization behaves differently between training and evaluation\n",
        "    train_accs.append(evaluate_metric(model, train_iter, correct))\n",
        "    test_accs.append(evaluate_metric(model, test_iter, correct))\n",
        "\n",
        "    end_time = time.perf_counter()\n",
        "\n",
        "    print(f'Training accuracy: {train_accs[-1]}. Testing accuracy: {test_accs[-1]}. Duration: {end_time - start_time:.3f}s.') # Computes and displays training/testing dataset accuracy.\n",
        "\n",
        "plt.plot(losses) # Plots the loss for each training batch\n",
        "plt.xlabel('Training batch')\n",
        "plt.ylabel('Cross entropy loss')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(list(map(lambda x: x.cpu(),train_accs)), label='Training accuracy')\n",
        "plt.plot(list(map(lambda x: x.cpu(),test_accs)), label='Testing accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "87089849",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_accs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest train accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mmax\u001b[39m(\u001b[43mtrain_accs\u001b[49m)))\n\u001b[1;32m      2\u001b[0m highest_value_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(train_accs), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest test accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(test_accs[highest_value_index]))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_accs' is not defined"
          ]
        }
      ],
      "source": [
        "print('best train accuracy: {}'.format(max(train_accs)))\n",
        "highest_value_index = max(enumerate(train_accs), key=lambda x: x[1])[0]\n",
        "print('best test accuracy: {}'.format(test_accs[highest_value_index]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0c52db",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
