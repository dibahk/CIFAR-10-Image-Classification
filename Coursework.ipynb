{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4fca06-f3df-4d3d-8465-c493f7879612",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85307fef-752a-4a8b-86d4-fb6f5d2f3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cd635c-7e1e-453a-8324-c2cf1c1812da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to understand this function for now.\n",
    "def load_data_CIFAR10(batch_size, resize=None):\n",
    "    \"\"\"Download the CIFAR10 dataset and then load it into memory.\"\"\"\n",
    "    trans = [torchvision.transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, torchvision.transforms.Resize(resize))\n",
    "    trans = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.CIFAR10(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=2),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86b1a98-2bd4-4d28-8aa9-b4e8536adb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # Defines the batch size\n",
    "train_iter, test_iter = load_data_CIFAR10(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecba6e7-eb01-4ee4-93c4-9ec60f808e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_iter)) # Requests the first training batch\n",
    "print(X.size()) # 256 images per batch. Each image is represented by a 1 x 28 x 28 tensor (number of channels x height x width). The images are grayscale, so there is a single channel.\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aead49bf-f489-49a1-ad95-73c425f20715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc = nn.Linear(out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(x)\n",
    "        out1 = self.conv1(out)\n",
    "        out2 = self.conv2(out)\n",
    "        out3 = self.conv3(out)\n",
    "        out4 = self.conv4(out)\n",
    "        out5 = self.conv5(out)\n",
    "        \n",
    "        # Average pooling\n",
    "        avg_pool = x.\n",
    "        avg_pool = avg_pool.view(avg_pool.size(0), -1)\n",
    "        # Weighted average calculation\n",
    "        weights = torch.sigmoid(self.fc(avg_pool))\n",
    "        print(weights.type())\n",
    "        # Weighted sum\n",
    "        weighted_sum = (out1 + out2 + out3 + out4 + out5) * weights.view(-1,1,1,1)\n",
    "        \n",
    "        return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb6ae26-f43d-424b-915b-f421766d7619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvBlock(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applies Xavier initialization if the `torch.nn.Module` is `torch.nn.Linear` or `torch.nn.Conv2d`\n",
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "num_outputs = 10\n",
    "model = ConvBlock(in_channels=3, out_channels=num_outputs)\n",
    "model.apply(init_weights) # Applies `init_weights` to every `torch.nn.Module` inside `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62987da8-567b-4690-8e9c-2d0a05481ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8fb2b4-1828-4960-81a1-49c84469adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f79f66-bf58-4a62-912a-b4b0931a9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(logits, y):\n",
    "    y_hat = logits.argmax(axis=1) # Finds the column with the highest value for each row of `logits`.\n",
    "    return (y_hat == y).float().sum() # Computes the number of times that `y_hat` and `y` match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440558aa-4038-48a2-9668-ea8b5a882e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metric(model, data_iter, metric):\n",
    "    \"\"\"Compute the average `metric` of the model on a dataset.\"\"\"\n",
    "    c = torch.tensor(0.)\n",
    "    n = torch.tensor(0.)\n",
    "    for X, y in data_iter:\n",
    "        logits = model(X)\n",
    "        c += metric(logits, y)\n",
    "        n += len(y)\n",
    "\n",
    "    return c / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698f82c-1c72-4e07-9305-e07e0c612058",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training accuracy: {evaluate_metric(model, train_iter, correct)}. Testing accuracy: {evaluate_metric(model, test_iter, correct)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45b272-c01e-4e47-8e17-7a7e608f8db5",
   "metadata": {},
   "source": [
    "# Basic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4bfbd-ceea-4b51-97fa-09d673d615d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b41e7467-ee60-42c8-bc44-875ffc24eb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5916,  0.5676, -1.0415,  0.2531,  1.1415, -1.0663],\n",
       "         [ 1.0914,  0.5812,  0.7329, -0.9620, -3.5427, -0.9107],\n",
       "         [ 0.1481, -0.6351, -2.2436,  0.2195,  0.3712, -0.2928],\n",
       "         [-0.3627, -0.1971, -1.1930,  0.7793, -0.3895,  1.8926],\n",
       "         [ 0.6179,  1.7252, -1.0225, -0.3343, -0.7708, -1.1098],\n",
       "         [-0.8818,  0.1688, -0.0045,  0.5856, -0.9097, -0.2356]],\n",
       "\n",
       "        [[-0.9179,  0.8336, -0.8736, -0.5851,  0.9430,  0.1678],\n",
       "         [ 1.1078,  0.6509,  0.2739,  0.2685,  0.1837, -0.4887],\n",
       "         [ 0.1076, -1.4711, -0.1499,  1.0199,  1.2663,  1.3709],\n",
       "         [-0.8724, -0.8335,  0.5277, -1.7724,  1.4742,  0.6399],\n",
       "         [-0.3226,  0.7655,  0.9605, -0.1787,  0.4703, -1.9245],\n",
       "         [-1.9839, -1.3509, -0.2614, -0.0918, -1.8255, -0.7549]],\n",
       "\n",
       "        [[ 0.1341,  0.6445,  0.7236, -0.3718, -1.1775, -0.1703],\n",
       "         [ 0.8173, -1.1339, -0.3453,  0.7949, -0.0057,  0.5891],\n",
       "         [ 1.2043,  1.0888,  0.1014, -2.1153, -0.5242, -0.2361],\n",
       "         [ 0.5098,  0.5529,  0.3398, -2.0270, -0.3535,  1.3578],\n",
       "         [ 2.2456,  0.7079, -0.0439,  1.6147, -1.6629,  0.1261],\n",
       "         [ 1.3471,  0.7019,  1.9844, -0.9387,  0.5293, -0.4642]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = torch.randn(3,6,6)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d41057c-f725-494c-bbe4-7b7a831c6e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.1000, 3.4000, 5.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "n = torch.Tensor([[[1,2,6,4,7],[2,4,3,5,7]],[[1,1,4,3,2],[2,2,7,5,7]], [[1,4,8,4,7],[2,4,8,5,7]]])\n",
    "m = []\n",
    "for i in range(n.size()[0]):\n",
    "    m.append((float(n[i].flatten().mean())))\n",
    "m = torch.Tensor(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0cd44b9-c7ff-4546-bee4-08ef382df462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(3, 5)\n",
    "    def forward(self, x):\n",
    "        out  = self.fc1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b89bd00-cceb-4b54-8c05-c9145cddca14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m k \u001b[38;5;241m=\u001b[39m Model()\n\u001b[0;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m k(\u001b[43mm\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "k = Model()\n",
    "out = k(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ff0d21-e530-4f8e-994a-bde7be049a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockGen(nn.Module):\n",
    "    # Creating Intermediate Blocks\n",
    "    # the length of param indicates the number of intermediate blocks\n",
    "    # each parameter is then inside the param for convolutional layers\n",
    "    def __init__(self, in_channels, out_channels, c, layers, paddings, strides, kernels):\n",
    "        super(BlockGen, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        convolutions = nn.ModuleList\n",
    "        \n",
    "        for i in c:\n",
    "            convs = nn.ModuleList()\n",
    "            for j in range(layers[i]):\n",
    "                convs.append(nn.Conv2d(in_channels[i][j], out_channels[i][j], kernel_size=kernels[i][j],stride= strides[i][j], padding= paddings[i][j]))\n",
    "            covolutions.append(convs)\n",
    "        self.model = convolutions\n",
    "        # the fully-connected layer turning m to a to calculate the weights of convolutional layer in the final equation\n",
    "        self.a = nn.Linear(in_channels, len(param))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m = []\n",
    "        for i in range(x.size()[0]):\n",
    "            m.append((float(x[i].flatten().mean())))\n",
    "        m = torch.Tensor(m)\n",
    "        weights = self.a(m)\n",
    "        # creating the convolutional neurons in the layer of the block\n",
    "        x = self.relu(x)\n",
    "        layer = []\n",
    "        for conv in self.model:\n",
    "            layer.append(conv(x))\n",
    "        return layer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d49ca46-e833-480e-8901-7dd53fe67112",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2093479193.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    class OutBlock:\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class OutBlock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f91b7f49-3c31-42db-9be7-542537e00dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{'L': 3,'kernel_size':1 , 'stride':1, 'padding':0}, {'out':3, 'L': 3,'kernel_size':2 , 'stride':3, 'padding':1}, {'out':2, 'L': 5,'kernel_size':2 , 'stride':1, 'padding':0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "46cf72e3-001c-4d4a-8a9a-de0a52949617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L': 3, 'kernel_size': 1, 'stride': 1, 'padding': 0}\n",
      "{'out': 3, 'L': 3, 'kernel_size': 2, 'stride': 3, 'padding': 1}\n",
      "{'out': 2, 'L': 5, 'kernel_size': 2, 'stride': 1, 'padding': 0}\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(param):\n",
    "    print(param[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e94b33b-0144-4ed5-b58d-b0cbab403175",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmod\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mod' is not defined"
     ]
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c519e-7681-4f72-9546-f4b62aaf11d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b36f43-d48d-49b1-b45b-5a30f153f3d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (4252390199.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    mod = Blo\"ckGen(param=param, in_channels=3, out_channels=10)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "mod = Blo\"ckGen(param=param, in_channels=3, out_channels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7a643aa4-6c75-40cd-8f03-4b734488dbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mod(n)\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ecac8036-a2a0-4d43-a700-1296cd511396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c70bb-8efc-45a8-affa-17439e5ad912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a096265e-0a6d-4579-b472-dae3894896ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = nn.Conv2d()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
